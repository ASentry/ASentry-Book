{"./":{"url":"./","title":"简介","keywords":"","body":"Introduction Copyright © ASentry 2020 all right reserved，powered by Gitbook该文章修订时间： 2020-09-29 09:53:32 "},"MoriningFlower/":{"url":"MoriningFlower/","title":"朝花夕拾","keywords":"","body":"朝花夕拾 Copyright © ASentry 2020 all right reserved，powered by Gitbook该文章修订时间： 2020-09-29 14:50:42 "},"Essay/":{"url":"Essay/","title":"随笔","keywords":"","body":"随笔 我们之所以战斗不是为了改变世界，而是为了不让世界改变我们。——《熔炉》 Copyright © ASentry 2020 all right reserved，powered by Gitbook该文章修订时间： 2020-10-03 21:34:43 "},"Essay/GoldenLine.html":{"url":"Essay/GoldenLine.html","title":"佳句","keywords":"","body":"佳句 我们的失败不是证明了我们的无能，而是证明了这座城市的颜色，是黑的。——《熔炉》 冬天之所以那么冷是为了告诉大家身边人的温暖有多重要。世界上最美丽最珍贵的，反而是听不见且看不清的，只能用心才能感受得到。——《熔炉》 每一桩罪案背后都有一公升的眼泪。——《狂探》 正如他们所说的那样,洞悉过人性以后才会明白,无论你是否做好了准备,生活都是一场随时可能被‘踢掉凳子’的绞刑。——《狂探》 有时候,你足够善良、足够热爱生活,却依旧无法阻挡这世上有着不可控制的人性之恶。——《狂探》 我认为,他们说得很对,究其根本,社会不公和缺乏教育才是滋生犯罪的土壤,才是最根本的原因!——《狂探》 我们都是行走在城市里孤独的人。在北京生活的人都知道，偌大的北京城，看起来人声鼎沸，可谁和谁又都没有关系，这是一个你哭得撕心裂肺，却没人停下来问你怎么了的地方。但这里也是所有温暖诉求的地方，你能在这里找到爱情，也能找到遗憾，城市永远不会变，它永远冰冷并且温暖地存在着，这就是北京。——《我有故事，你有酒吗？》 一生至少该有一次 ， 为了某个人而忘了自己 ， 不求有结果 ， 不求同行 ， 不求曾经拥有 ， 甚至不求你爱我 ， 只求在我最美的年华里 ， 遇到你 。       ——徐志摩 孤独这两个字拆开来看，有孩童，有瓜果，有小犬，有蚊蝇，足以撑起一个盛夏傍晚间的巷子口，人情味十足。稚儿擎瓜柳棚下，细犬逐蝶窄巷中，人间繁华多笑语，惟我空余两鬓风。——孩童水果猫狗飞蝇当然热闹，可都和你无关，这就叫孤独。——林语堂 这个世界并没有我们看上去那么的简单，人各有命上天注定，有人天生为王，有人落草为寇，脚下的路如果不是你自己的选择，那旅程的终点在哪儿也没人知道，你会走到哪会碰到谁都不一定。 ——镇魂街 读书给了我们一个到此一游的机会，让我们看遍了大观园，当我们以为我们余生都会在大观园生活的时候，生存却悄悄的告诉我们，我们很有可能，未来还是要回到来的地方。那一刻，我深深感受到了生存带来的无奈。 至亲离去的那一瞬间，通常不会使人感到悲伤，真正会让你感到悲痛的是打开冰箱的那半盒牛奶、那窗台上随风微曳的绿萝、那安静折叠在床上的绒被，还有那深夜里洗衣机传来的阵阵喧哗。 Copyright © ASentry 2020 all right reserved，powered by Gitbook该文章修订时间： 2020-10-10 15:36:27 "},"DeepLearning/":{"url":"DeepLearning/","title":"深度学习","keywords":"","body":"深度学习 深度学习相关笔记 Copyright © ASentry 2020 all right reserved，powered by Gitbook该文章修订时间： 2020-09-30 10:17:25 "},"DeepLearning/Convolutional-Neural-Networks.html":{"url":"DeepLearning/Convolutional-Neural-Networks.html","title":"卷积神经网络","keywords":"","body":"卷积神经网络 1.链式法则计算：y=f(x),z=g(y),∂z/∂x=∂z/∂y⋅∂y/∂x 2.卷积核奇偶选择:奇数卷积核，奇数有利于原始数据对应。也可以选择偶数卷积核 3.上采样：输入图像经过卷积神经网络提取特征后，输出尺寸会变小，而将图像恢复到原来尺寸，实现小分辨率到大分辨率的映射操作叫上采样。上采样常见三种方法：双线性差值(bilinear)，反卷积(Transposed Convolution)，反池化(Unpooling) 4.反卷积是一种特殊的正向卷积，先按照一定的比例通过补0来扩大输入图像的尺寸，接着旋转卷积核，再进行正向卷积。反卷积只能恢复尺寸，不能回复数值。 5.ReLU:将负值数据置0 6.池化就是降维 7.全卷积结构(FCN):没有全连接层。特点：1.输入图片大小无限制2.空间信息有丢失3.参数更少，表达能力更强 8.全局部卷积连接的缺陷： 预处理：大量对准，对对准要求高，原始信息可能丢失 卷积参数数量大，模型收敛难度大，需要大量数据 模型可扩展性3差，基本限于人脸计算 9.逆卷积：生成图片有更好的连贯性，有更好的空间表达能力 10.灰度化：在RGB模型中，如果R=G=B，则彩色表示一种灰度颜色，其中R=G=B的值叫做灰度值，因此灰度图像每个像素只需一个字节存放灰度值（又称强度值，亮度值），灰度范围为0-255 11.灰度化两种方法： 方法一 灰度化后的R=（处理前的R + 处理前的G +处理前的B）/ 3 灰度化后的G=（处理前的R + 处理前的G +处理前的B）/ 3 灰度化后的B=（处理前的R + 处理前的G +处理前的B）/ 3 方法二 灰度化后的R = 处理前的R 0.3+ 处理前的G 0.59 +处理前的B * 0.11 灰度化后的G = 处理前的R 0.3+ 处理前的G 0.59 +处理前的B * 0.11 灰度化后的B = 处理前的R 0.3+ 处理前的G 0.59 +处理前的B * 0.11 12.贝叶斯公式：P(A|B)=P(B|A)*P(A)/P(B) 13.IoU=A∩B/A∪B 14.如果导数为负，则参数向更大的方向走，反之，向更小的方向走。学习率控制变化速度 15.越复杂的model不一定会获得更好的结果，可能发生过拟合(overfit) 16.传统梯度下降： 17.动量梯度下降： 18.Dropout:每次更新参数时都要随机丢掉一部分神经元，对新的神经网络进行训练。训练时准确率下降，但测试时会上升。测试时不dropout,但权重要乘以(1-p%)(p%是训练时设置的dropout rate) 19.RNN:将之前的输出存贮起来，下次使用后更新 20.Elman NetWork&Jordan Network 21.Bidirectional RNN:看的范围比较广 22.LSTM: 23.RNN换为LSTM的原因：LSTM可以解决梯度消失的问题。 24.CTC:用NULL代替重复符号 25.Self-Attention： Copyright © ASentry 2020 all right reserved，powered by Gitbook该文章修订时间： 2020-10-06 15:20:47 "}}